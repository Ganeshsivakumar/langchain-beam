"use strict";(globalThis.webpackChunkdocs_site=globalThis.webpackChunkdocs_site||[]).push([[827],{6239:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"guide/langchain-Beam-transforms","title":"langchain-Beam-transforms","description":"This section provides a conceptual guide on the transforms offered by Langchain-Beam library.","source":"@site/docs/guide/langchain-Beam-transforms.md","sourceDirName":"guide","slug":"/guide/langchain-Beam-transforms","permalink":"/langchain-beam/docs/guide/langchain-Beam-transforms","draft":false,"unlisted":false,"editUrl":"https://github.com/Ganeshsivakumar/langchain-beam/tree/main/docs/docs-site/docs/docs/guide/langchain-Beam-transforms.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Apache Beam","permalink":"/langchain-beam/docs/guide/apache-beam"},"next":{"title":"Templates","permalink":"/langchain-beam/docs/category/templates"}}');var i=t(4848),s=t(8453);const r={},o=void 0,d={},l=[{value:"LLM Transform",id:"llm-transform",level:2},{value:"Input and Output",id:"input-and-output",level:4},{value:"Usage in Pipeline",id:"usage-in-pipeline",level:3},{value:"Execution:",id:"execution",level:3},{value:"Embedding Transform",id:"embedding-transform",level:2}];function c(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.p,{children:["This section provides a conceptual guide on the transforms offered by Langchain-Beam library.\nFor explanation about what is transform (PTransform) and other Apache Beam-related concepts, please refer to this ",(0,i.jsx)(n.a,{href:"/langchain-beam/docs/guide/apache-beam",children:"page"})]}),"\n",(0,i.jsx)(n.h2,{id:"llm-transform",children:"LLM Transform"}),"\n",(0,i.jsx)(n.p,{children:"The LLM transform integrates Large Language Models as PTransform"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"LangchainBeam"})," is an Apache Beam ",(0,i.jsx)(n.code,{children:"PTransform"})," that uses LangChain\u2019s ChatModel interface,\nto integrate LLMs from various providers like OpenAI. The transform accepts a ",(0,i.jsx)(n.code,{children:"String"})," as input, where each element is processed using a specified language model via a ",(0,i.jsx)(n.code,{children:"LangchainModelHandler"})," and yields a ",(0,i.jsx)(n.code,{children:"LangchainBeamOutput"}),", containing the model\u2019s responses for each input element."]}),"\n",(0,i.jsx)(n.h4,{id:"input-and-output",children:"Input and Output"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Input"}),": A ",(0,i.jsx)(n.code,{children:"PCollection<String>"})," representing the input strings to be processed by the language model."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Output"}),": A ",(0,i.jsx)(n.code,{children:"PCollection<LangchainBeamOutput>"})," containing the model\u2019s responses and the corresponding input elements."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"usage-in-pipeline",children:"Usage in Pipeline"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"LangchainBeam"})," transform can be instantiated in pipeline using the ",(0,i.jsx)(n.code,{children:"run()"})," method and it takes a\n",(0,i.jsx)(n.code,{children:"LangchainModelHandler"})," as input."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"LangchainBeam.run(handler);\n"})}),"\n",(0,i.jsxs)(n.p,{children:["the ",(0,i.jsx)(n.code,{children:"LangchainModelHandler"})," stores the instruction prompt and model options, which together define how the language model will process each input element. Here\u2019s how these inputs can be provided:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Instruction Prompt:"})," The instruction prompt is a string that specifies the task or operation the language model should perform on the input data. It provides the necessary context and instructions for the model to generate appropriate outputs. For example, a prompt might instruct the model to \u201cCategorize the product review as Positive or Negative.\u201d"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Model Options:"})," A configuration object that specifies the provide, language model to use and provides other options of the model."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:'// Define the instruction prompt for LLM\nString instructionPrompt = "Categorize the product review as Positive or Negative.";\n\n// Create model options\nOpenAiModelOptions modelOptions = OpenAiModelOptions.builder()\n                .modelName("gpt-4o-mini")\n                .apiKey(apiKey)\n                .build();\n\n// Initialize LangchainModelHandler with the prompt and model options\nLangchainModelHandler handler = new LangchainModelHandler(instructionPrompt, modelOptions);\n\n//create transform\nLangchainBeam.run(handler);\n\n'})}),"\n",(0,i.jsx)(n.h3,{id:"execution",children:"Execution:"}),"\n",(0,i.jsxs)(n.p,{children:["During pipeline execution the transform will use the model to process the input element based on the\nprovided instruction prompt and the transform with output a ",(0,i.jsx)(n.code,{children:"LangchainBeamOutput"})," object, which encapsulates the ",(0,i.jsx)(n.strong,{children:"The model's response"})," and the ",(0,i.jsx)(n.strong,{children:"The input element"})," that was processed."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-java",children:"LangchainBeamOutput out;\nout.getOutput() // returns model's output\nout.getInputElement() // returns input element\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"LangchainBeamOutput"})," is a Serializable class and it is serialized using default coder provided by Beam. So, the object can be directly passed on to next transform without any aditional coder step."]}),"\n",(0,i.jsx)(n.h2,{id:"embedding-transform",children:"Embedding Transform"}),"\n",(0,i.jsxs)(n.p,{children:["This transform integrates Embedding models as ",(0,i.jsx)(n.code,{children:"PTransform"})," to generate vector embeddings for text in beam pipeline."]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var a=t(6540);const i={},s=a.createContext(i);function r(e){const n=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);