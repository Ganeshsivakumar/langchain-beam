"use strict";(self.webpackChunkdocs_site=self.webpackChunkdocs_site||[]).push([[547],{1631:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/flinkoutput-1b631f88a128bc59c736a49207c03737.png"},2680:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/flinkterminal-985daed70dc8de184d7c975e47d6f16d.png"},3983:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/flinkversions-9dcd4fcab0aadc99664096d15e3fc79f.png"},5028:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>r,default:()=>h,frontMatter:()=>l,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"tutorials/sentiment-analysis-flink-runner","title":"Run sentiment analysis pipeline using Apache Flink runner","description":"This notebook shares how to perform sentiment analysis in beam pipeline using LLM transform and run it using Apache Flink runner.","source":"@site/docs/tutorials/sentiment-analysis-flink-runner.md","sourceDirName":"tutorials","slug":"/tutorials/sentiment-analysis-flink-runner","permalink":"/langchain-beam/docs/tutorials/sentiment-analysis-flink-runner","draft":false,"unlisted":false,"editUrl":"https://github.com/Ganeshsivakumar/langchain-beam/tree/main/docs/docs-site/docs/docs/tutorials/sentiment-analysis-flink-runner.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Build a RAG pipeline using Beam","permalink":"/langchain-beam/docs/tutorials/create-rag-pipeline"},"next":{"title":"How to run Apache Flink Locally","permalink":"/langchain-beam/docs/tutorials/setup-flink"}}');var s=i(4848),a=i(8453);const l={},r="Run sentiment analysis pipeline using Apache Flink runner",o={},c=[{value:"<strong>1. Create the project \ud83d\udce6</strong>",id:"1-create-the-project-",level:2},{value:"<strong>2. Create pipeline \ud83d\udee0\ufe0f</strong>",id:"2-create-pipeline-\ufe0f",level:2},{value:"Define the Instruction Prompt",id:"define-the-instruction-prompt",level:3},{value:"Configure the Model and Options",id:"configure-the-model-and-options",level:3},{value:"Store Prompt and Model Options",id:"store-prompt-and-model-options",level:3},{value:"Build the Beam Pipeline",id:"build-the-beam-pipeline",level:3},{value:"<strong>3. Run Pipeline on Apache Flink Cluster \ud83d\ude80</strong>",id:"3-run-pipeline-on-apache-flink-cluster-",level:2},{value:"Set up Apache Flink",id:"set-up-apache-flink",level:3},{value:"Choose the Compatible Flink Version",id:"choose-the-compatible-flink-version",level:4},{value:"Start the Flink Cluster",id:"start-the-flink-cluster",level:3},{value:"Submit Job",id:"submit-job",level:3},{value:"Build the Pipeline JAR",id:"build-the-pipeline-jar",level:4},{value:"Submit the Job to the Flink Cluster",id:"submit-the-job-to-the-flink-cluster",level:4},{value:"Job Output",id:"job-output",level:3}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"run-sentiment-analysis-pipeline-using-apache-flink-runner",children:"Run sentiment analysis pipeline using Apache Flink runner"})}),"\n",(0,s.jsxs)(n.p,{children:["This notebook shares how to perform sentiment analysis in beam pipeline using ",(0,s.jsx)(n.a,{href:"../../guide/langchain-Beam-transforms#llm-transform",children:"LLM transform"})," and run it using Apache Flink runner."]}),"\n",(0,s.jsx)(n.p,{children:"Apache Flink is a powerful, distributed stream and batch data processing engine known for its scalability, fault tolerance, and stateful processing capabilities. In the context of Apache Beam, Flink serves as a robust runner that can efficiently execute complex pipelines, including those involving large language models (LLMs)."}),"\n",(0,s.jsx)(n.p,{children:"By leveraging the Flink runner, your Beam pipeline can handle continuous data streams while integrating seamlessly with Langchain-Beam\u2019s LLM transforms for NLP tasks like sentiment analysis."}),"\n",(0,s.jsx)(n.p,{children:"The pipeline"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"loads the csv file that contains reviews and feedback of a product"}),"\n",(0,s.jsx)(n.li,{children:"uses LLM transform to categorize reviews and get sentiment"}),"\n",(0,s.jsx)(n.li,{children:"print the model output"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"1-create-the-project-",children:(0,s.jsx)(n.strong,{children:"1. Create the project \ud83d\udce6"})}),"\n",(0,s.jsxs)(n.p,{children:["Create a java maven project and import necessary dependencies in your ",(0,s.jsx)(n.code,{children:"pom.xml"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:"\x3c!-- Add Flink runner dependency and make sure that the runner\ndependency version is compatible with `beam-sdks-java-core` version --\x3e\n        <dependency>\n            <groupId>org.apache.beam</groupId>\n            <artifactId>beam-runners-flink-1.18</artifactId>\n            <version>2.61.0</version>\n        </dependency>\n        \x3c!-- Use latest version of Langchain-Beam --\x3e\n        <dependency>\n            <groupId>io.github.ganeshsivakumar</groupId>\n            <artifactId>langchain-beam</artifactId>\n            <version>0.3.0</version>\n        </dependency>\n        \x3c!-- Apache Beam --\x3e\n        <dependency>\n            <groupId>org.apache.beam</groupId>\n            <artifactId>beam-sdks-java-core</artifactId>\n            <version>2.61.0</version>\n        </dependency>\n"})}),"\n",(0,s.jsxs)(n.p,{children:["The Final JAR file of the project should be a ",(0,s.jsx)(n.a,{href:"https://stackoverflow.com/questions/19150811/what-is-a-fat-jar",children:"Fat Jar"}),', i.e, the Jar file of the project should include all the dependencies that the pipeline is using, May be that\'s why its called "Fat" Jar \ud83d\udc37']}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'\x3c!-- Use Maven Shade Plugin to create Fat Jar --\x3e\n    <build>\n        <plugins>\n            \x3c!-- Maven Shade Plugin --\x3e\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-shade-plugin</artifactId>\n                <version>3.2.1</version>\n                <executions>\n                    <execution>\n                        <phase>package</phase>\n                        <goals>\n                            <goal>shade</goal>\n                        </goals>\n                        <configuration>\n                            <createDependencyReducedPom>false</createDependencyReducedPom>\n                            <artifactSet>\n                                <includes>\n                                    \x3c!-- Include everything --\x3e\n                                    <include>*:*</include>\n                                </includes>\n                            </artifactSet>\n                            <filters>\n                                <filter>\n                                    <artifact>*:*</artifact>\n                                    <excludes>\n                                        \x3c!-- Exclude signature files --\x3e\n                                        <exclude>META-INF/*.SF</exclude>\n                                        <exclude>META-INF/*.RSA</exclude>\n                                        <exclude>META-INF/*.DSA</exclude>\n                                    </excludes>\n                                </filter>\n                            </filters>\n                            <transformers>\n                                \x3c!-- Merge META-INF/services files --\x3e\n                                <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer" />\n                            </transformers>\n                            <shadedArtifactAttached>false</shadedArtifactAttached>\n                            <minimizeJar>false</minimizeJar>\n                        </configuration>\n                    </execution>\n                </executions>\n            </plugin>\n    </build>\n'})}),"\n",(0,s.jsx)(n.h2,{id:"2-create-pipeline-\ufe0f",children:(0,s.jsx)(n.strong,{children:"2. Create pipeline \ud83d\udee0\ufe0f"})}),"\n",(0,s.jsx)(n.p,{children:"Now, let's define the Apache Beam pipeline. We'll start by importing the required modules and setting up the necessary components."}),"\n",(0,s.jsx)(n.h3,{id:"define-the-instruction-prompt",children:"Define the Instruction Prompt"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"instruction prompt"})," guides the model on how to process each input element in the pipeline. In this case, our goal is to analyze the sentiment of product reviews. We define the prompt as:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'String prompt = "Categorize the product review as Positive or Negative.";\n'})}),"\n",(0,s.jsx)(n.p,{children:"During pipeline execution, the model will use this prompt to process input elements, which consist of a list of product reviews."}),"\n",(0,s.jsx)(n.h3,{id:"configure-the-model-and-options",children:"Configure the Model and Options"}),"\n",(0,s.jsxs)(n.p,{children:["Next, we need to define the model and its options. We'll use OpenAI\u2019s ",(0,s.jsx)(n.strong,{children:"GPT-4o-mini"})," to process the reviews. Langchain-Beam provides the ",(0,s.jsx)(n.code,{children:"OpenAiModelOptions"})," class, which allows us to specify:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"The model name"}),"\n",(0,s.jsx)(n.li,{children:"The API key"}),"\n",(0,s.jsxs)(n.li,{children:["Other parameters such as ",(0,s.jsx)(n.strong,{children:"temperature"})," for response variability"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'String apiKey = System.getenv("OPENAI_API_KEY");\n\n        // Create model options with the model and its parameters\n        OpenAiModelOptions modelOptions = OpenAiModelOptions.builder()\n                .modelName("gpt-4o-mini")\n                .apiKey(apiKey)\n                .build();\n'})}),"\n",(0,s.jsx)(n.h3,{id:"store-prompt-and-model-options",children:"Store Prompt and Model Options"}),"\n",(0,s.jsxs)(n.p,{children:["We encapsulate both the prompt and model options inside a ",(0,s.jsx)(n.code,{children:"LangchainModelHandler"})," object. This handler manages how the model is invoked within the pipeline."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:"// create LangchainModelHandler to pass it to LangchainBeam transform\nLangchainModelHandler handler = new LangchainModelHandler(modelOptions, prompt);\n"})}),"\n",(0,s.jsx)(n.h3,{id:"build-the-beam-pipeline",children:"Build the Beam Pipeline"}),"\n",(0,s.jsx)(n.p,{children:"Now, we construct the Beam pipeline, Since we are using Apache Flink runner, we'll set the flink pipeline specfic\noptions and the create the beam pipeline that will:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Load"})," the product reviews data from a local file"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Apply"})," the LLM transform to analyze sentiment"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Print"})," the model's output"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'// create flink pipeline specfic options\n        FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n        options.setJobName("product-review-job");\n        options.setRunner(FlinkRunner.class);\n        options.setParallelism(2); // parallel execution\n\n        // create beam pipeline\n        Pipeline p = Pipeline.create(options);\n\n        p.apply(TextIO.read().from("/home/ganesh/Downloads/product_reviews.csv"))// load data\n                .apply(LangchainBeam.run(handler)) // apply the LangchainBeam transform.\n                .apply(ParDo.of(new DoFn<LangchainBeamOutput, Void>() {\n\n                    @ProcessElement\n                    public void processElement(@Element LangchainBeamOutput out) {\n                        // print model output\n                        System.out\n                                .println("Model Output: " + out.getOutput() + " input element: "\n                                        + out.getInputElement());\n                    }\n                }));\n\n        // run pipeline\n        p.run();\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Full Code Reference:"}),"\nFor the complete implementation with imported modules, check out the GitHub repository:"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://github.com/Ganeshsivakumar/langchain-beam/blob/main/example/langchain-beam-example/src/main/java/com/langchainbeam/example/ApacheFlinkExample.java",children:"\ud83d\udd17 Langchain-Beam Flink Example"})}),"\n",(0,s.jsx)(n.h2,{id:"3-run-pipeline-on-apache-flink-cluster-",children:(0,s.jsx)(n.strong,{children:"3. Run Pipeline on Apache Flink Cluster \ud83d\ude80"})}),"\n",(0,s.jsx)(n.p,{children:"Now that we have created the pipeline and its transform components, we can run it as a job in Apache Flink. We\u2019ll start by setting up a local Flink cluster."}),"\n",(0,s.jsx)(n.h3,{id:"set-up-apache-flink",children:"Set up Apache Flink"}),"\n",(0,s.jsxs)(n.p,{children:["To execute the pipeline using the Flink Runner, you need to set up an Apache Flink cluster. Follow the Flink ",(0,s.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/resource-providers/standalone/overview/#preparation",children:"Setup Quickstart"})," to install and configure Flink."]}),"\n",(0,s.jsx)(n.h4,{id:"choose-the-compatible-flink-version",children:"Choose the Compatible Flink Version"}),"\n",(0,s.jsx)(n.p,{children:"Ensure that you install an Apache Flink version compatible with Apache Beam and the Flink Runner. For this example, we are using:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Apache Beam"}),": ",(0,s.jsx)(n.code,{children:"artifactId: beam-sdks-java-core, version: 2.61.0"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Flink Runner"}),": ",(0,s.jsx)(n.code,{children:"artifactId: beam-runners-flink-1.18, version: 2.61.0"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Apache Flink"}),": ",(0,s.jsx)(n.code,{children:"1.18.1"})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Refer to the compatibility table from Apache Beam for selecting the correct Flink version:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Flink Version Compatibility Table",src:i(3983).A+"",width:"1043",height:"1080"})}),"\n",(0,s.jsxs)(n.p,{children:["To download the appropriate Flink version, visit the ",(0,s.jsx)(n.a,{href:"https://flink.apache.org/downloads/",children:"Flink downloads page"}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"start-the-flink-cluster",children:"Start the Flink Cluster"}),"\n",(0,s.jsxs)(n.p,{children:["Once you have downloaded and extracted the correct Flink version, start a ",(0,s.jsx)(n.strong,{children:"standalone cluster in Session Mode"})," as described in the ",(0,s.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/deployment/resource-providers/standalone/overview/#starting-a-standalone-cluster-session-mode",children:"Flink documentation"}),"."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"start cluster in terminal",src:i(2680).A+"",width:"1308",height:"323"})}),"\n",(0,s.jsxs)(n.p,{children:["After starting the cluster, verify that the Flink Web UI is running by navigating to ",(0,s.jsx)(n.a,{href:"http://localhost:8081",children:"http://localhost:8081/"}),". If the cluster is running successfully, you should see the Flink dashboard:"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"dashboard",src:i(7378).A+"",width:"1914",height:"1155"})}),"\n",(0,s.jsx)(n.h3,{id:"submit-job",children:"Submit Job"}),"\n",(0,s.jsx)(n.p,{children:"Now that we have set up the Flink cluster and configured our Apache Beam pipeline, we can submit the job for execution."}),"\n",(0,s.jsx)(n.h4,{id:"build-the-pipeline-jar",children:"Build the Pipeline JAR"}),"\n",(0,s.jsx)(n.p,{children:"Before submitting the job, we need to package our Apache Beam pipeline as a JAR file. Navigate to your project directory and run:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sh",children:"mvn clean package\n"})}),"\n",(0,s.jsxs)(n.p,{children:["This will generate a JAR file inside the ",(0,s.jsx)(n.code,{children:"target/"})," directory. Make sure to locate this JAR, as it will be used in the next step"]}),"\n",(0,s.jsx)(n.h4,{id:"submit-the-job-to-the-flink-cluster",children:"Submit the Job to the Flink Cluster"}),"\n",(0,s.jsx)(n.p,{children:"To submit the job, use the following command:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sh",children:"./bin/flink run -c com.example.Main /home/ganesh/Dev/beampipeline/flinkrun/lbflink/target/lbflink-1.0-SNAPSHOT.jar\n"})}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Note:"})," Update your Main class name and jar file path in command."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"job-output",children:"Job Output"}),"\n",(0,s.jsxs)(n.p,{children:["Once the job is submitted, head over to the Flink dashboard web UI to monitor execution\nand you should see your job listed under ",(0,s.jsx)(n.strong,{children:"Running Jobs"})]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"job",src:i(9519).A+"",width:"1915",height:"1153"})}),"\n",(0,s.jsx)(n.p,{children:"Click on the Job ID in the Flink dashboard to access detailed execution metrics, logs, and operator statistics."}),"\n",(0,s.jsx)(n.p,{children:"Once the pipeline completes execution, review the logs to see the model\u2019s output printed by the job."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"output",src:i(1631).A+"",width:"1915",height:"1153"})}),"\n",(0,s.jsx)(n.p,{children:"Congratulations! \ud83c\udf89 You\u2019ve successfully deployed and executed\na LangChain-Beam pipeline on Apache Flink."}),"\n",(0,s.jsx)(n.p,{children:"Now, feel free to experiment with different prompts, models, or data sources and different use cases to further enhance your pipeline. Happy coding! \ud83d\udca1"})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},7378:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/flinkdashboard-49449ed67c3d96c4226790f06f420296.png"},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>r});var t=i(6540);const s={},a=t.createContext(s);function l(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),t.createElement(a.Provider,{value:n},e.children)}},9519:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/flinkjob-58d7954bff5b50be20ced26b9cf2577a.png"}}]);